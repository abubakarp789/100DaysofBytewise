{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Date          4849 non-null   int64 \n",
      " 1   Article_ID    4849 non-null   int64 \n",
      " 2   Country_Code  4849 non-null   object\n",
      " 3   Sold_Units    4849 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 151.7+ KB\n",
      "None\n",
      "               Date  Article_ID   Sold_Units\n",
      "count  4.849000e+03  4849.00000  4849.000000\n",
      "mean   2.017794e+07  2314.55331     1.966797\n",
      "std    5.981690e+03  1813.23926     2.373171\n",
      "min    2.017010e+07   332.00000     1.000000\n",
      "25%    2.017093e+07   409.00000     1.000000\n",
      "50%    2.018041e+07  1923.00000     1.000000\n",
      "75%    2.018092e+07  3448.00000     2.000000\n",
      "max    2.019021e+07  5984.00000   101.000000\n"
     ]
    }
   ],
   "source": [
    "# ### Step 1: Data Collection and Preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Historical_Data.csv')\n",
    "# #### 1. Load the Dataset\n",
    "# The dataset has been loaded successfully and here is the first few rows of the data:\n",
    "\n",
    "# ```\n",
    "#        Date  Article_ID Country_Code  Sold_Units\n",
    "# 0  20170817        1132           AT           1\n",
    "# 1  20170818        1132           AT           1\n",
    "# 2  20170821        1132           AT           1\n",
    "# 3  20170822        1132           AT           1\n",
    "# 4  20170906        1132           AT           1\n",
    "# ```\n",
    "\n",
    "\n",
    "\n",
    "# #### 3. Feature Engineering\n",
    "# We'll extract year and month from the 'Date' column.\n",
    "\n",
    "# ```python\n",
    "# data['Date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
    "# data['Year'] = data['Date'].dt.year\n",
    "# data['Month'] = data['Date'].dt.month\n",
    "# data.head()\n",
    "# ```\n",
    "\n",
    "# ### Step 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "# #### 1. Descriptive Statistics\n",
    "# We'll summarize the main characteristics of the dataset.\n",
    "\n",
    "# ```python\n",
    "# data.describe()\n",
    "# ```\n",
    "\n",
    "# #### 2. Data Visualization\n",
    "# We'll visualize the sales distribution and sales over time.\n",
    "\n",
    "# ```python\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Sales distribution\n",
    "# sns.histplot(data['Sold_Units'], kde=True)\n",
    "# plt.title('Sales Distribution')\n",
    "# plt.show()\n",
    "\n",
    "# # Sales over time\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(data['Date'], data['Sold_Units'])\n",
    "# plt.title('Sales Over Time')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Sold Units')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# #### 3. Correlation Analysis\n",
    "# We'll identify the correlation between different features.\n",
    "\n",
    "# ```python\n",
    "# correlation_matrix = data.corr()\n",
    "# sns.heatmap(correlation_matrix, annot=True)\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# ### Step 4: Probability Distributions\n",
    "\n",
    "# #### 1. Plot Probability Distributions\n",
    "# We'll plot and analyze the probability distributions of the key features.\n",
    "\n",
    "# ```python\n",
    "# sns.kdeplot(data['Sold_Units'])\n",
    "# plt.title('Sold Units Probability Distribution')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# #### 2. Check Normality\n",
    "# We'll use Q-Q plots to check if the data follows a normal distribution.\n",
    "\n",
    "# ```python\n",
    "# from scipy import stats\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# stats.probplot(data['Sold_Units'], dist=\"norm\", plot=plt)\n",
    "# plt.title('Q-Q Plot of Sold Units')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# ### Step 5: Linear Regression Model\n",
    "\n",
    "# #### 1. Split the Data\n",
    "# We'll divide the dataset into training and testing sets.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = data[['Year', 'Month']]  # Example features\n",
    "# y = data['Sold_Units']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# ```\n",
    "\n",
    "# #### 2. Train the Model\n",
    "# We'll use sklearn to train a linear regression model.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# ```\n",
    "\n",
    "# #### 3. Evaluate the Model\n",
    "# We'll evaluate the model's performance using metrics like Mean Squared Error (MSE) and R-squared.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# mse, r2\n",
    "# ```\n",
    "\n",
    "# ### Step 6: Interpretation and Reporting\n",
    "\n",
    "# #### 1. Interpret the Results\n",
    "# We'll analyze the model coefficients and their significance.\n",
    "\n",
    "# ```python\n",
    "# coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "# coefficients\n",
    "# ```\n",
    "\n",
    "# #### 2. Visualize the Predictions\n",
    "# We'll plot the actual vs predicted sales.\n",
    "\n",
    "# ```python\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.xlabel('Actual Sold Units')\n",
    "# plt.ylabel('Predicted Sold Units')\n",
    "# plt.title('Actual vs Predicted Sold Units')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# #### 3. Report Findings\n",
    "# We'll summarize the key findings, including descriptive statistics, data visualizations, model performance, and insights gained.\n",
    "\n",
    "# ---\n",
    "\n",
    "# Let's execute these steps one by one.\n",
    "\n",
    "# ### Step 1: Data Collection and Preparation\n",
    "\n",
    "# - The dataset has been loaded successfully.\n",
    "# - The dataset contains 4849 entries and 4 columns: `Date`, `Article_ID`, `Country_Code`, and `Sold_Units`.\n",
    "# - There are no missing values or duplicates in the dataset.\n",
    "# - We extracted `Year` and `Month` from the `Date` column for further analysis.\n",
    "\n",
    "# ### Step 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "# #### 1. Descriptive Statistics\n",
    "# We have summarized the main characteristics of the dataset.\n",
    "\n",
    "# #### 2. Data Visualization\n",
    "# Let's visualize the sales distribution and sales over time.\n",
    "\n",
    "# ```python\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Sales distribution\n",
    "# sns.histplot(data['Sold_Units'], kde=True)\n",
    "# plt.title('Sales Distribution')\n",
    "# plt.show()\n",
    "\n",
    "# # Sales over time\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(data['Date'], data['Sold_Units'])\n",
    "# plt.title('Sales Over Time')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Sold Units')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# #### 3. Correlation Analysis\n",
    "# We'll identify the correlation between different features.\n",
    "\n",
    "# ```python\n",
    "# correlation_matrix = data.corr()\n",
    "# sns.heatmap(correlation_matrix, annot=True)\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# ### Step 4: Probability Distributions\n",
    "\n",
    "# #### 1. Plot Probability Distributions\n",
    "# We'll plot and analyze the probability distributions of the key features.\n",
    "\n",
    "# ```python\n",
    "# sns.kdeplot(data['Sold_Units'])\n",
    "# plt.title('Sold Units Probability Distribution')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# #### 2. Check Normality\n",
    "# We'll use Q-Q plots to check if the data follows a normal distribution.\n",
    "\n",
    "# ```python\n",
    "# from scipy import stats\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# stats.probplot(data['Sold_Units'], dist=\"norm\", plot=plt)\n",
    "# plt.title('Q-Q Plot of Sold Units')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# Let's execute the EDA steps first.\n",
    "\n",
    "# ### Step 3: Exploratory Data Analysis (EDA) Results\n",
    "\n",
    "# 1. **Sales Distribution:**\n",
    "#    - The sales distribution is heavily right-skewed, indicating most sales are of lower quantities, with a few instances of higher sales.\n",
    "\n",
    "# 2. **Sales Over Time:**\n",
    "#    - Sales show fluctuations over time, with no clear upward or downward trend.\n",
    "\n",
    "# 3. **Correlation Analysis:**\n",
    "#    - There is no strong correlation between the variables (`Year`, `Month`, `Sold_Units`), as seen in the correlation heatmap.\n",
    "\n",
    "# ### Step 4: Probability Distributions\n",
    "\n",
    "# 1. **Sales Probability Distribution:**\n",
    "#    - The distribution of sold units is right-skewed, similar to the histogram.\n",
    "\n",
    "# 2. **Q-Q Plot:**\n",
    "#    - The Q-Q plot indicates that the `Sold_Units` data does not follow a normal distribution, as the points deviate significantly from the reference line.\n",
    "\n",
    "# ### Step 5: Linear Regression Model\n",
    "\n",
    "# #### 1. Split the Data\n",
    "# We'll divide the dataset into training and testing sets.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = data[['Year', 'Month']]  # Example features\n",
    "# y = data['Sold_Units']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# ```\n",
    "\n",
    "# #### 2. Train the Model\n",
    "# We'll use sklearn to train a linear regression model.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# ```\n",
    "\n",
    "# #### 3. Evaluate the Model\n",
    "# We'll evaluate the model's performance using metrics like Mean Squared Error (MSE) and R-squared.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# mse, r2\n",
    "# ```\n",
    "\n",
    "# #### 4. Interpret the Results\n",
    "# We'll analyze the model coefficients and their significance.\n",
    "\n",
    "# ```python\n",
    "# coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "# coefficients\n",
    "# ```\n",
    "\n",
    "# #### 5. Visualize the Predictions\n",
    "# We'll plot the actual vs predicted sales.\n",
    "\n",
    "# ```python\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.xlabel('Actual Sold Units')\n",
    "# plt.ylabel('Predicted Sold Units')\n",
    "# plt.title('Actual vs Predicted Sold Units')\n",
    "# plt.show()\n",
    "# ```\n",
    "\n",
    "# Let's execute the linear regression model steps.\n",
    "\n",
    "# It seems like I can’t do more advanced data analysis right now. Please try again later. \n",
    "\n",
    "# In the meantime, I can provide you with the code you need to complete the linear regression analysis on your dataset. You can run it in your local environment or any Python-enabled platform.\n",
    "\n",
    "# ```python\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from scipy import stats\n",
    "\n",
    "# # Load the dataset\n",
    "# file_path = 'path_to_your_dataset/Historical_Data.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # Convert Date column to datetime\n",
    "# data['Date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
    "# data['Year'] = data['Date'].dt.year\n",
    "# data['Month'] = data['Date'].dt.month\n",
    "\n",
    "# # Split the data\n",
    "# X = data[['Year', 'Month']]  # Example features\n",
    "# y = data['Sold_Units']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# y_pred = model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # Interpret the results\n",
    "# coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "\n",
    "# # Visualize the predictions\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.xlabel('Actual Sold Units')\n",
    "# plt.ylabel('Predicted Sold Units')\n",
    "# plt.title('Actual vs Predicted Sold Units')\n",
    "# plt.show()\n",
    "\n",
    "# print('Mean Squared Error:', mse)\n",
    "# print('R-squared:', r2)\n",
    "# print('Coefficients:', coefficients)\n",
    "# ```\n",
    "\n",
    "# You can copy this code and run it in your environment. If you encounter any issues or need further assistance, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Date          4849 non-null   int64 \n",
      " 1   Article_ID    4849 non-null   int64 \n",
      " 2   Country_Code  4849 non-null   object\n",
      " 3   Sold_Units    4849 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 151.7+ KB\n",
      "None\n",
      "               Date  Article_ID   Sold_Units\n",
      "count  4.849000e+03  4849.00000  4849.000000\n",
      "mean   2.017794e+07  2314.55331     1.966797\n",
      "std    5.981690e+03  1813.23926     2.373171\n",
      "min    2.017010e+07   332.00000     1.000000\n",
      "25%    2.017093e+07   409.00000     1.000000\n",
      "50%    2.018041e+07  1923.00000     1.000000\n",
      "75%    2.018092e+07  3448.00000     2.000000\n",
      "max    2.019021e+07  5984.00000   101.000000\n"
     ]
    }
   ],
   "source": [
    "# #### 2. Inspect the Dataset\n",
    "# Let's inspect the dataset further.\n",
    "\n",
    "# ```python\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "# ```\n",
    "\n",
    "# We'll proceed to check for missing values and duplicates.\n",
    "\n",
    "# ### Step 2: Data Cleaning\n",
    "\n",
    "# #### 1. Handle Missing Values\n",
    "# We'll check for missing values.\n",
    "\n",
    "# ```python\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values\n",
    "# ```\n",
    "\n",
    "# #### 2. Remove Duplicates\n",
    "# We'll check and remove duplicates if any.\n",
    "\n",
    "# ```python\n",
    "data = data.drop_duplicates()\n",
    "# ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
